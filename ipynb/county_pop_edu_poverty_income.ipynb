{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import sys, os\n",
    "\n",
    "cd = os.path.split(os.getcwd())[0]\n",
    "if cd not in sys.path:\n",
    "    sys.path.append(cd)\n",
    "\n",
    "from lib import noaa, bexarcrime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sauce](https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = pd.read_excel('../data/Education.xls', skiprows=4)\n",
    "\n",
    "# state and areas are named nicely in this dataset and will be kept for the later 'join'\n",
    "# columns[-4:] include most recent data for adults eduction\n",
    "# I chose the most recent because its not like the total number of HS dropouts is going to change THAT much\n",
    "edu = edu[['FIPS Code', 'State', 'Area name'] + list(edu.columns[-4:])]\n",
    "edu.rename(columns={'FIPS Code':'FIPS', \\\n",
    "                    'Area name':'County',\\\n",
    "                    'Percent of adults with less than a high school diploma, 2011-2015':'p_no_HS_dip', \\\n",
    "                    'Percent of adults with a high school diploma only, 2011-2015':'p_HS_dip',\\\n",
    "                    'Percent of adults completing some college or associate\\'s degree, 2011-2015':'p_some_college',\\\n",
    "                    'Percent of adults with a bachelor\\'s degree or higher, 2011-2015':'p_college_dip'}, inplace=True)\n",
    "edu = edu.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_excel('../data/PopulationEstimates.xls', skiprows=2)\n",
    "\n",
    "# average the columns\n",
    "cols = ['POP_ESTIMATE_2010','POP_ESTIMATE_2011','POP_ESTIMATE_2012','POP_ESTIMATE_2013','POP_ESTIMATE_2014','POP_ESTIMATE_2015','POP_ESTIMATE_2016']\n",
    "pop['avgpop'] = pop[cols].sum(axis=1) / len(cols)\n",
    "\n",
    "# more averaging\n",
    "cols = ['N_POP_CHG_2010','N_POP_CHG_2011','N_POP_CHG_2012','N_POP_CHG_2013','N_POP_CHG_2014','N_POP_CHG_2015','N_POP_CHG_2016']\n",
    "pop['dpop/dt'] = pop[cols].sum(axis=1) / len(cols)\n",
    "\n",
    "# only pull FIPS code, population, and dp\n",
    "pop = pop[['FIPS', 'avgpop', 'dpop/dt']]\n",
    "pop = pop.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pov = pd.read_excel('../data/PovertyEstimates.xls', skiprows=3)\n",
    "\n",
    "# only select poverty\n",
    "pov = pov[['FIPStxt', 'POVALL_2015']]\n",
    "pov.rename(columns={'FIPStxt':'FIPS'}, inplace=True)\n",
    "pov = pov.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = pd.read_excel('../data/Unemployment.xls', skiprows=9)\n",
    "\n",
    "#avg unemployment\n",
    "cols = ['Unemployment_rate_2007', 'Unemployment_rate_2008', 'Unemployment_rate_2009', 'Unemployment_rate_2010', 'Unemployment_rate_2011', 'Unemployment_rate_2012', 'Unemployment_rate_2013', 'Unemployment_rate_2014', 'Unemployment_rate_2015', 'Unemployment_rate_2016']\n",
    "emp['avg_unemployed_rate'] = emp[cols].sum(axis=1) / len(cols)\n",
    "\n",
    "#only pull average and income\n",
    "emp = emp[['FIPStxt', 'avg_unemployed_rate', 'Median_Household_Income_2015']]\n",
    "emp.rename(columns={'FIPStxt':'FIPS'}, inplace=True)\n",
    "emp = emp.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = edu.join([pop,pov,emp], how='outer')\n",
    "df = df.where(df.State != 'PR').dropna(how='all') ## Puerto Rico has unreliable data\n",
    "\n",
    "#pull out nationwide data\n",
    "us = df.iloc[0]\n",
    "df = df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out statewide data\n",
    "s = [x for x in range(1000,75000,1000)]\n",
    "states = df.loc[s].dropna(how='all')\n",
    "\n",
    "# all thats left is county level data\n",
    "df = df.drop(states.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
