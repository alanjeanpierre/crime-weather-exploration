{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "cd = os.path.split(os.getcwd())[0]\n",
    "if cd not in sys.path:\n",
    "    sys.path.append(cd)\n",
    "\n",
    "from lib import noaa, bexarcrime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sauce A](https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data/)\n",
    "\n",
    "[sauce B](http://www.icpsr.umich.edu/icpsrweb/NACJD/studies/35019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using crime reports, not arrests \n",
    "crime = pd.read_csv('../data/CountyCrimeReports.tsv', sep='\\t')\n",
    "crime['FIPS'] = crime['FIPS_ST'] * 1000 + crime['FIPS_CTY']\n",
    "crime['vcrime'] = crime['MURDER'] + crime['RAPE'] + crime['ROBBERY'] + crime['AGASSLT']\n",
    "\n",
    "# vcrime_rate should be vcrime/population, not total crime\n",
    "#crime['vcrime_rate'] = crime['P1VLNT']/crime['P1TOT']\n",
    "\n",
    "\n",
    "crime = crime.set_index('FIPS')\n",
    "crime = crime[['COVIND', 'vcrime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu = pd.read_excel('../data/Education.xls', skiprows=4)\n",
    "\n",
    "# state and areas are named nicely in this dataset and will be kept for the later 'join'\n",
    "# columns[-4:] include most recent data for adults eduction\n",
    "# I chose the most recent because its not like the total number of HS dropouts is going to change THAT much\n",
    "edu = edu[['FIPS Code', 'State', 'Area name'] + list(edu.columns[-4:])]\n",
    "edu.rename(columns={'FIPS Code':'FIPS', \\\n",
    "                    'Area name':'County',\\\n",
    "                    'Percent of adults with less than a high school diploma, 2011-2015':'p_no_HS_dip', \\\n",
    "                    'Percent of adults with a high school diploma only, 2011-2015':'p_HS_dip',\\\n",
    "                    'Percent of adults completing some college or associate\\'s degree, 2011-2015':'p_some_college',\\\n",
    "                    'Percent of adults with a bachelor\\'s degree or higher, 2011-2015':'p_college_dip'}, inplace=True)\n",
    "edu = edu.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop = pd.read_excel('../data/PopulationEstimates.xls', skiprows=2)\n",
    "\n",
    "# average the columns\n",
    "cols = ['POP_ESTIMATE_2010','POP_ESTIMATE_2011','POP_ESTIMATE_2012','POP_ESTIMATE_2013','POP_ESTIMATE_2014','POP_ESTIMATE_2015','POP_ESTIMATE_2016']\n",
    "pop['avgpop'] = pop[cols].sum(axis=1) / len(cols)\n",
    "\n",
    "# more averaging\n",
    "cols = ['N_POP_CHG_2010','N_POP_CHG_2011','N_POP_CHG_2012','N_POP_CHG_2013','N_POP_CHG_2014','N_POP_CHG_2015','N_POP_CHG_2016']\n",
    "pop['dpop/dt'] = pop[cols].sum(axis=1) / len(cols)\n",
    "\n",
    "# only pull FIPS code, population, and dp\n",
    "pop = pop[['FIPS', 'avgpop', 'dpop/dt']]\n",
    "pop = pop.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pov = pd.read_excel('../data/PovertyEstimates.xls', skiprows=3)\n",
    "# only select poverty percentage\n",
    "pov = pov[['FIPStxt', 'PCTPOVALL_2015']]\n",
    "pov.rename(columns={'FIPStxt':'FIPS', 'PCTPOVALL_2015':'p_impoverished'}, inplace=True)\n",
    "pov = pov.set_index('FIPS')\n",
    "pov.p_impoverished = pd.to_numeric(pov.p_impoverished, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = pd.read_excel('../data/Unemployment.xls', skiprows=9)\n",
    "\n",
    "#avg unemployment\n",
    "cols = ['Unemployment_rate_2007', 'Unemployment_rate_2008', 'Unemployment_rate_2009', 'Unemployment_rate_2010', 'Unemployment_rate_2011', 'Unemployment_rate_2012', 'Unemployment_rate_2013', 'Unemployment_rate_2014', 'Unemployment_rate_2015', 'Unemployment_rate_2016']\n",
    "emp['p_unempl'] = emp[cols].sum(axis=1) / len(cols)\n",
    "\n",
    "#only pull average and income\n",
    "emp = emp[['FIPStxt', 'p_unempl', 'Median_Household_Income_2015']]\n",
    "emp.rename(columns={'FIPStxt':'FIPS', 'Median_Household_Income_2015':'med_income'}, inplace=True)\n",
    "emp = emp.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = edu.join([pop,pov,emp,crime], how='outer')\n",
    "df = df.where(df.State != 'PR').dropna(how='all') ## Puerto Rico has unreliable data\n",
    "\n",
    "#pull out nationwide data\n",
    "us = df.iloc[0]\n",
    "df = df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull out statewide data\n",
    "s = [x for x in range(1000,75000,1000)]\n",
    "states = df.loc[s].dropna(how='all')\n",
    "\n",
    "# all thats left is county level data\n",
    "df = df.drop(states.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing data\n",
    "df['p_dpop'] = df['dpop/dt']/df['avgpop']\n",
    "df['vcrime_rate'] = 100000 * df['vcrime']/df['avgpop']\n",
    "df = df.drop(['dpop/dt', 'vcrime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins data into high, medium, and low (based on national quantiles) for grouping\n",
    "binned = pd.DataFrame({c : pd.qcut(df[c], 3, labels=['L', 'M', 'H']) for c in df.drop(['State', 'County', 'COVIND'], axis=1).columns}).join(df[['State', 'County', 'COVIND']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = list(reversed(binned.columns[:-3]))\n",
    "#groups = groups.reverse()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all counties grouped by H/M/L rates of whatever\n",
    "c = binned.dropna(how='all').groupby(groups)\n",
    "c.count().where(c.count().State > 6).dropna().sort_values('State', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#highest crime counties in US\n",
    "# note that high city crime does not necessarily match high county crime\n",
    "# eg: chicago is high crime, but it's split between 2 counties\n",
    "# St Louis has the highest crime, but it's its own county, so it tops this list as well\n",
    "df.sort_values('vcrime_rate', ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original values of the first row ^^^\n",
    "# such that cities have high crime rate, high unemployment, low education, etc\n",
    "selection = ('H','H','L','H','H','L','L','H','L','M')\n",
    "for x in groups:\n",
    "    print(\"%10s \" %x[:10], end='')\n",
    "print('')\n",
    "for x in selection:\n",
    "    print(\"%10s \" %x[:10], end='')\n",
    "df.loc[c.get_group(selection).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apparently the worst counties to be in in Texas\n",
    "# High violent crime rate, high rate of unemployment, and high populations\n",
    "TX = binned.dropna(how='all').groupby(['vcrime_rate', 'p_unempl', 'avgpop'])\n",
    "df.loc[TX.get_group(('H', 'H', 'H')).index].where(df.State == 'TX').dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
